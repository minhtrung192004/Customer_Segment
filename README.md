# üìä PH√ÇN KH√öC KH√ÅCH H√ÄNG  V√Ä ƒê·ªÄ XU·∫§ CHI·∫æN L∆Ø·ª¢C KINH DOANH D·ª∞A TR√äN RFM, PCA V√Ä PH√ÇN TICH CORHORT

D·ª± √°n n√†y ph√¢n t√≠ch d·ªØ li·ªáu giao d·ªãch v√† nh√¢n kh·∫©u h·ªçc c·ªßa kh√°ch h√†ng t·ª´ m·ªôt c√¥ng ty b√°n l·∫ª xe ƒë·∫°p t·∫°i √öc, nh·∫±m kh√°m ph√° c√°c nh√≥m kh√°ch h√†ng ch√≠nh, theo d√µi h√†nh vi ti√™u d√πng v√† ƒë·ªÅ xu·∫•t c√°c chi·∫øn l∆∞·ª£c marketing d·ª±a tr√™n d·ªØ li·ªáu.

---

## üìÅ T·ªïng Quan D·ª± √Ån

- **M·ª•c ti√™u**: Ph√¢n kh√∫c kh√°ch h√†ng, ph√¢n t√≠ch h√†nh vi v√† x√¢y d·ª±ng chi·∫øn l∆∞·ª£c gi·ªØ ch√¢n, marketing c√° nh√¢n h√≥a.
- **D·ªØ li·ªáu**: Giao d·ªãch, th√¥ng tin nh√¢n kh·∫©u h·ªçc, ƒë·ªãa ch·ªâ kh√°ch h√†ng v√† kh√°ch h√†ng m·ªõi (nƒÉm 2017).
- **C√¥ng c·ª• s·ª≠ d·ª•ng**: Python, Power BI, PCA, KMeans, RFM, ph√¢n t√≠ch cohort.

---

## üìå C·∫•u Tr√∫c D·ª± √Ån

### 1. üè¢ B·ªëi C·∫£nh

Hi·ªÉu ƒë∆∞·ª£c h√†nh vi kh√°ch h√†ng l√† y·∫øu t·ªë then ch·ªët gi√∫p doanh nghi·ªáp c·∫°nh tranh v√† ph√°t tri·ªÉn b·ªÅn v·ªØng. D·ª± √°n √°p d·ª•ng c√°c k·ªπ thu·∫≠t ph√¢n t√≠ch d·ªØ li·ªáu hi·ªán ƒë·∫°i (RFM, PCA, KMeans, Cohort Analysis) ƒë·ªÉ kh√°m ph√° c√°c nh√≥m kh√°ch h√†ng, theo d√µi t·ª∑ l·ªá gi·ªØ ch√¢n v√† h·ªó tr·ª£ quy·∫øt ƒë·ªãnh chi·∫øn l∆∞·ª£c cho doanh nghi·ªáp.

---

### 2. üßπ L√†m S·∫°ch D·ªØ Li·ªáu

**C√°c b·ªô d·ªØ li·ªáu ƒë∆∞·ª£c x·ª≠ l√Ω g·ªìm:**

#### a. `Transactions`
- Kh√¥ng c√≥ d√≤ng tr√πng l·∫∑p;
- Lo·∫°i b·ªè d√≤ng thi·∫øu gi√° tr·ªã (`brand`, `product_line`, `standard_cost`);
- Chu·∫©n h√≥a c·ªôt ng√†y (`transaction_date`) th√†nh ƒë·ªãnh d·∫°ng th·ªùi gian;
- T√≠nh to√°n bi√™n l·ª£i nhu·∫≠n (`profit_margin`).

#### b. `Customer Demographic`
- Thay th·∫ø gi√° tr·ªã thi·∫øu trong `job_title`, `industry_category` b·∫±ng ‚ÄúOthers‚Äù;
- Lo·∫°i b·ªè kh√°ch h√†ng c√≥ `DOB` b·∫•t h·ª£p l√Ω (nƒÉm 1843) v√† `gender = "U"`;
- T√≠nh th√™m bi·∫øn `customer_age`, `customer_value_score`.

#### c. `Customer Address`
- G·ªôp v·ªõi b·∫£ng demographic qua `customer_id`;
- D√πng `postcode` v√† `property_valuation` ƒë·ªÉ ph√¢n v√πng theo ƒë·ªãa l√Ω.

#### d. `New Customer List`
- L√†m s·∫°ch t∆∞∆°ng t·ª± b·∫£ng nh√¢n kh·∫©u h·ªçc;
- Lo·∫°i b·ªè d√≤ng ch·ª©a gi√° tr·ªã sai ƒë·ªãnh d·∫°ng;
- Chu·∫©n h√≥a ƒë·ªÉ s·∫µn s√†ng d·ª± ƒëo√°n ph√¢n kh√∫c.

---

### 3. üë• Ph√¢n Kh√∫c Kh√°ch H√†ng

- **RFM Scoring**: T√≠nh Recency, Frequency v√† Monetary cho t·ª´ng kh√°ch h√†ng.
- **PCA**: Gi·∫£m chi·ªÅu d·ªØ li·ªáu tr∆∞·ªõc khi ph√¢n c·ª•m.
- **KMeans**: Ph√¢n c·ª•m v√† x√°c ƒë·ªãnh s·ªë l∆∞·ª£ng nh√≥m t·ªëi ∆∞u (s·ª≠ d·ª•ng Elbow Method).
  - G·ªìm 4 nh√≥m ch√≠nh:
    - Kh√°ch h√†ng trung th√†nh
    - Kh√°ch h√†ng gi√° tr·ªã cao
    - Kh√°ch h√†ng kh√¥ng c√≤n ho·∫°t ƒë·ªông
    - Kh√°ch h√†ng m·ªõi/ti·ªÅm nƒÉng
- **TSNE**: Tr·ª±c quan h√≥a k·∫øt qu·∫£ ph√¢n c·ª•m.

---

### 4. üìä Ph√¢n T√≠ch D·ªØ Li·ªáu (EDA)

Ph√¢n t√≠ch t·ª´ t·ªïng quan ƒë·∫øn chi ti·∫øt theo t·ª´ng nh√≥m:

- **Hi·ªáu qu·∫£ kinh doanh**
  - Doanh thu theo th·ªùi gian, khu v·ª±c, danh m·ª•c s·∫£n ph·∫©m.
  - L·ª£i nhu·∫≠n theo th∆∞∆°ng hi·ªáu v√† nh√≥m h√†ng.
  - T·ª∑ l·ªá h·ªßy ƒë∆°n theo lo·∫°i s·∫£n ph·∫©m.

- **H√†nh vi kh√°ch h√†ng**
  - Ph√¢n t√≠ch nh√¢n kh·∫©u h·ªçc: ƒë·ªô tu·ªïi, gi·ªõi t√≠nh, ngh·ªÅ nghi·ªáp, t√†i s·∫£n.
  - T·∫ßn su·∫•t mua h√†ng, gi√° tr·ªã trung b√¨nh ƒë∆°n h√†ng.
  - **Cohort Analysis**: ph√¢n t√≠ch t·ª∑ l·ªá gi·ªØ ch√¢n theo th√°ng.

Tr·ª±c quan h√≥a b·∫±ng:
- Bi·ªÉu ƒë·ªì c·ªôt, ƒë∆∞·ªùng, heatmap, Sankey chart (Python + Power BI)

---

### üß† 5. M√¥ h√¨nh h√≥a & D·ª± ƒëo√°n kh√°ch h√†ng m·ªõi

#### 5.1. M√¥ h√¨nh d·ªØ li·ªáu v√† Pipeline
- D·ªØ li·ªáu ƒë∆∞·ª£c chia th√†nh t·∫≠p hu·∫•n luy·ªán (80%) v√† ki·ªÉm tra (20%).
- S·ª≠ d·ª•ng `ColumnTransformer` ƒë·ªÉ chu·∫©n h√≥a v√† m√£ h√≥a ƒë·∫∑c tr∆∞ng (standardization cho bi·∫øn s·ªë, One-Hot Encoding cho bi·∫øn ph√¢n lo·∫°i).
- T·ªëi ∆∞u h√≥a hyperparameter th√¥ng qua `GridSearchCV` (cho Logistic Regression, MLP) v√† `RandomizedSearchCV` (cho Random Forest, XGBoost, HistGradientBoosting).

---

#### 5.2. C√°c m√¥ h√¨nh s·ª≠ d·ª•ng
| M√¥ h√¨nh                     | K·ªπ thu·∫≠t t·ªëi ∆∞u             | Cross-validation Score |
|-----------------------------|------------------------------|-------------------------|
| Logistic Regression         | GridSearchCV                 | 0.7563                  |
| Random Forest               | RandomizedSearchCV           | 0.9718                  |
| HistGradientBoosting        | RandomizedSearchCV           | 0.9820                  |
| XGBoost                     | RandomizedSearchCV           | 0.9586                  |
| MLP Classifier              | GridSearchCV                 | 0.9738                  |

---

#### 5.3. K·∫øt qu·∫£ hu·∫•n luy·ªán c√°c m√¥ h√¨nh

| M√¥ h√¨nh                     | Accuracy (Train) | Accuracy (Test) | CV Score |
|-----------------------------|------------------|------------------|----------|
| Logistic Regression         | 75.64%           | 75.40%           | 75.63%   |
| Random Forest               | 99.40%           | 98.03%           | 97.18%   |
| HistGradientBoosting        | 99.92%           | 99.02%           | 98.20%   |
| XGBoost                     | 98.71%           | 96.33%           | 95.86%   |
| MLP Classifier              | 99.22%           | 97.93%           | 97.38%   |

üéØ **Nh·∫≠n x√©t**:
- HistGradientBoosting v√† Random Forest ƒë·∫°t hi·ªáu su·∫•t cao, kh√¥ng b·ªã overfitting.
- XGBoost c√≥ d·∫•u hi·ªáu overfitting nh·∫π.
- Logistic Regression cho k·∫øt qu·∫£ th·∫•p nh·∫•t, ph√π h·ª£p v·ªõi m√¥ h√¨nh baseline.

---

#### 5.4. Hyperparameter T·ªëi ∆∞u

| M√¥ h√¨nh                     | Hyperparameter                          | Gi√° tr·ªã t·ªëi ∆∞u                                   |
|-----------------------------|------------------------------------------|--------------------------------------------------|
| **Logistic Regression**     | `penalty`                                | `'l1'`                                           |
|                             | `C`                                      | `10`                                             |
|                             | `solver`                                 | `'liblinear'`                                    |
| **Random Forest**           | `n_estimators`                           | `204`                                            |
|                             | `criterion`                              | `'entropy'`                                      |
|                             | `max_depth`                              | `18`                                             |
|                             | `max_features`                           | `'log2'`                                         |
|                             | `min_samples_split`                      | `7`                                              |
|                             | `min_samples_leaf`                       | `1`                                              |
| **HistGradientBoosting**    | `learning_rate`                          | `0.6799`                                         |
|                             | `l2_regularization`                      | `0.2293`                                         |
|                             | `max_leaf_nodes`                         | `119`                                            |
|                             | `min_samples_leaf`                       | `36`                                             |
|                             | `max_bins`                               | `74`                                             |
| **XGBoost**                 | `colsample_bytree`                       | `0.9212`                                         |
|                             | `gamma`                                  | `0.416`                                          |
|                             | `learning_rate`                          | `0.2391`                                         |
|                             | `max_depth`                              | `4`                                              |
|                             | `n_estimators`                           | `298`                                            |
|                             | `reg_alpha`                              | `0.1942`                                         |
|                             | `reg_lambda`                             | `0.5725`                                         |
|                             | `subsample`                              | `0.5479`                                         |
| **MLP Classifier**          | `hidden_layer_sizes`                     | `(100, 50)`                                      |
|                             | `activation`                             | `'tanh'`                                         |
|                             | `alpha`                                  | `0.01`                                           |
|                             | `solver`                                 | `'adam'`                                         |

---

#### 5.5. ƒê√°nh gi√° m√¥ h√¨nh b·∫±ng ROC & Classification Report

- **HistGradientBoosting** v√† **Random Forest** c√≥ AUC g·∫ßn 1.000 cho t·∫•t c·∫£ c√°c l·ªõp ‚Üí m√¥ h√¨nh ·ªïn ƒë·ªãnh, t·ªïng qu√°t t·ªët.
- **XGBoost** ƒë·∫°t AUC cao ·ªü l·ªõp 0 v√† 1, gi·∫£m nh·∫π ·ªü l·ªõp 2 v√† 3.
- **MLP Classifier** ho·∫°t ƒë·ªông t·ªët ·ªü l·ªõp ph·ªï bi·∫øn, nh∆∞ng c√≥ s·ª± gi·∫£m nh·∫π ·ªü l·ªõp √≠t d·ªØ li·ªáu.
- **Logistic Regression** c√≥ AUC th·∫•p, ƒë·∫∑c bi·ªát l√† l·ªõp 2 ch·ªâ ƒë·∫°t 0.7452 ‚Üí hi·ªáu su·∫•t k√©m h∆°n h·∫≥n.

---

#### 5.6. D·ª± ƒëo√°n kh√°ch h√†ng m·ªõi

- M√¥ h√¨nh XGBoost d·ª± ƒëo√°n hi·ªáu qu·∫£ c√°c ph√¢n kh√∫c kh√°ch h√†ng m·ªõi d·ª±a tr√™n h√†nh vi v√† ƒë·∫∑c ƒëi·ªÉm nh√¢n kh·∫©u h·ªçc.
- Nh√≥m kh√°ch h√†ng ti·ªÅm nƒÉng (high-value) c√≥ gi√° tr·ªã t√†i s·∫£n cao v√† th·ªùi gian g·∫Øn b√≥ d√†i, cho th·∫•y t√≠nh kh·∫£ thi trong vi·ªác ph√°t tri·ªÉn chi·∫øn l∆∞·ª£c chƒÉm s√≥c c√° nh√¢n h√≥a.

---

‚úÖ **K·∫øt lu·∫≠n**:
- **HistGradientBoosting** l√† l·ª±a ch·ªçn t·ªët nh·∫•t trong b√†i to√°n ph√¢n kh√∫c kh√°ch h√†ng m·ªõi.
- M√¥ h√¨nh c√≥ ƒë·ªô ch√≠nh x√°c cao, kh·∫£ nƒÉng t·ªïng qu√°t t·ªët v√† tr√°nh overfitting.

